# Script to further identify MD animal detections using classification models trained via MEWC
# MEWC - Mega Efficient Wildlife Classifier - University of Tasmania
# https://github.com/zaandahl/mewc

# It constsist of code that is specific for this kind of model architechture, and 
# code that is generic for all model architectures that will be run via EcoAssist.
# Written by Peter van Lunteren
# Latest edit by Peter van Lunteren on 22 May 2024

#############################################
############### MODEL GENERIC ###############
#############################################
# catch shell arguments
import sys
EcoAssist_files = str(sys.argv[1])
cls_model_fpath = str(sys.argv[2])
cls_detec_thresh = float(sys.argv[3])
cls_class_thresh = float(sys.argv[4])
smooth_bool = True if sys.argv[5] == 'True' else False
json_path = str(sys.argv[6])
temp_frame_folder =  None if str(sys.argv[7]) == 'None' else str(sys.argv[7])

##############################################
############### MODEL SPECIFIC ###############
##############################################
# imports
import os
import cv2
import yaml
import numpy as np
import tensorflow as tf
import tensorflow_addons as tfa
from tensorflow.keras.models import load_model

# load model
animal_model = load_model(cls_model_fpath, custom_objects={'loss': tfa.losses.SigmoidFocalCrossEntropy()})
img_size = animal_model.get_config()["layers"][0]["config"]["batch_input_shape"][1]

# check GPU availability
GPU_availability = True if len(tf.config.list_logical_devices('GPU')) > 0 else False

# read label map
def read_yaml(file_path):
    with open(file_path, 'r') as f:
        return yaml.safe_load(f)
class_map = read_yaml(os.path.join(os.path.dirname(cls_model_fpath), "class_list.yaml"))

# convert key:values if neccesary
def can_all_keys_be_converted_to_int(d):
    for key in d.keys():
        try:
            int(key)
        except ValueError:
            return False
    return True
if not can_all_keys_be_converted_to_int(class_map):
    class_map = {v: k for k, v in class_map.items()}

# predict from cropped image
# input: cropped PIL image
# output: unsorted classifications formatted as [['aardwolf', 2.3025326090220233e-09], ['african wild cat', 5.658252888451898e-08], ... ]
# no need to remove forbidden classes from the predictions, that will happen in infrence_lib.py
def get_classification(PIL_crop):
    img = np.array(PIL_crop)
    img = cv2.resize(img, (img_size, img_size))
    img = np.expand_dims(img, axis=0)
    pred = animal_model.predict(img, verbose=0)[0]
    class_ids = sorted(class_map.values())
    classifications = []
    for i in range(len(pred)):
        classifications.append([class_ids[i], float(pred[i])])
    return classifications

# method of removing background
# input: image = full image PIL.Image.open(img_fpath) <class 'PIL.JpegImagePlugin.JpegImageFile'>
# input: bbox = the bbox coordinates as read from the MD json - detection['bbox'] - [xmin, ymin, xmax, ymax]
# output: cropped image <class 'PIL.Image.Image'>
# each developer has its own way of padding, squaring, cropping, resizing etc
# it needs to happen exactly the same as on which the model was trained
# thanks Dan Morris: https://github.com/agentmorris/MegaDetector/blob/main/md_visualization/visualization_utils.py
def crop_image(image, bbox): 
    x1, y1, w_box, h_box = bbox
    ymin,xmin,ymax,xmax = y1, x1, y1 + h_box, x1 + w_box
    im_width, im_height = image.size
    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,
                                    ymin * im_height, ymax * im_height)
    left = max(left,0); right = max(right,0)
    top = max(top,0); bottom = max(bottom,0)
    left = min(left,im_width-1); right = min(right,im_width-1)
    top = min(top,im_height-1); bottom = min(bottom,im_height-1)
    image_cropped = image.crop((left, top, right, bottom))
    # resizing will be done in get_classification()
    return image_cropped


#############################################
############### MODEL GENERIC ###############
#############################################
# run main function
import EcoAssist.classification_utils.inference_lib as ea
ea.classify_MD_json(json_path = json_path,
                    GPU_availability = GPU_availability,
                    cls_detec_thresh = cls_detec_thresh,
                    cls_class_thresh = cls_class_thresh,
                    smooth_bool = smooth_bool,
                    crop_function = crop_image,
                    inference_function = get_classification,
                    temp_frame_folder = temp_frame_folder,
                    cls_model_fpath = cls_model_fpath)
